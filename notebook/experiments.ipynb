{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c2a7792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fea5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0e98e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9506b22",
   "metadata": {},
   "outputs": [],
   "source": [
    " GROQ_API_KEY=os.environ.get(\"GROQ_API_KEY\")\n",
    "model= ChatGroq(model=\"qwen/qwen3-32b\", api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77a81dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ChatGroq(model=\"qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3753fde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so the user is asking, \"What is the capital of France?\" Hmm, let me think. I remember from school that France is a country in Europe, and its capital is a major city. Let me recall... I think it\\'s Paris. Wait, isn\\'t Paris known for the Eiffel Tower and the Louvre? Yeah, that sounds right. Let me double-check to make sure I\\'m not mixing it up with another country. For example, Spain\\'s capital is Madrid, Germany\\'s is Berlin, Italy\\'s is Rome. So France\\'s should be Paris. I don\\'t think there\\'s any confusion there. Maybe they just want a straightforward answer. I should confirm if there are any other possible answers, but I\\'m pretty confident it\\'s Paris. Yeah, I\\'ll go with Paris as the capital of France.\\n</think>\\n\\nThe capital of France is **Paris**. Known for iconic landmarks such as the Eiffel Tower, the Louvre Museum, and Notre-Dame Cathedral, Paris is one of the most famous cities in the world and a major cultural, historical, and political center of France. \\n\\n**Answer:** Paris.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 236, 'prompt_tokens': 15, 'total_tokens': 251, 'completion_time': 0.472653879, 'prompt_time': 0.000398614, 'queue_time': 0.050847701, 'total_time': 0.473052493}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_f17c2eb555', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0e2f9c8b-d1f3-4db8-bb21-6f2af3c815dc-0', usage_metadata={'input_tokens': 15, 'output_tokens': 236, 'total_tokens': 251})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6de8fb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04f354fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "67a6f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy=embedding_model.embed_query(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7db54",
   "metadata": {},
   "source": [
    "## 1. Data INgestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bf1ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a529bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49dc1a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\sharma.rakesh\\\\Desktop\\\\Projects\\\\LLM_ops\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(), \"data\", \"sample.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51d40cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\sharma.rakesh\\\\Desktop\\\\Projects\\\\LLM_ops\\\\document_portal\\\\notebook'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dec265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=PyPDFLoader(os.path.join(os.getcwd(), \"data\", \"sample.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff9bfe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f14d1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba431da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## there is no determnitic way to split the text,we can try different chunk sizes and overlap\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000, \n",
    "                                             chunk_overlap=200,length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32f87f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6857109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4c7adff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'pdfTeX-1.40.25',\n",
       " 'creator': 'LaTeX with hyperref',\n",
       " 'creationdate': '2023-07-20T00:30:36+00:00',\n",
       " 'author': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2023-07-20T00:30:36+00:00',\n",
       " 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5',\n",
       " 'subject': '',\n",
       " 'title': '',\n",
       " 'trapped': '/False',\n",
       " 'source': 'c:\\\\Users\\\\sharma.rakesh\\\\Desktop\\\\Projects\\\\LLM_ops\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf',\n",
       " 'total_pages': 77,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4801dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\\nPunit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\\nYinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\\nIgor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\\nAlan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\\nRoss Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\\nAngela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "696f68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "check=embedding_model.embed_documents([docs[0].page_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19e5ceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_model.embed_documents([docs[0].page_content][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3bc6f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b7247f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in memory vector store\n",
    "vectorstore=FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1044349",
   "metadata": {},
   "source": [
    "## 2. Retrrieval processes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "86870a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_doc=vectorstore.similarity_search(\"What is a llama2 llm model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "32ab0a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='7738d961-0da7-40ab-97f2-29f8676a30b5', metadata={'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2023-07-20T00:30:36+00:00', 'author': '', 'keywords': '', 'moddate': '2023-07-20T00:30:36+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': '', 'title': '', 'trapped': '/False', 'source': 'c:\\\\Users\\\\sharma.rakesh\\\\Desktop\\\\Projects\\\\LLM_ops\\\\document_portal\\\\notebook\\\\data\\\\sample.pdf', 'total_pages': 77, 'page': 73, 'page_label': '74'}, page_content='Llama 1\\n7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\\nLlama 2\\n7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\\nFine-tuned')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c3b90c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 1\n",
      "7B 0.27 0.26 0.34 0.54 0.36 0.39 0.26 0.28 0.33 0.45 0.33 0.17 0.24 0.31 0.44 0.57 0.39 0.3513B 0.24 0.24 0.31 0.52 0.37 0.37 0.23 0.28 0.31 0.50 0.27 0.10 0.24 0.27 0.41 0.55 0.34 0.2533B 0.23 0.26 0.34 0.50 0.36 0.35 0.24 0.33 0.34 0.49 0.31 0.12 0.23 0.30 0.41 0.60 0.28 0.2765B 0.25 0.26 0.34 0.46 0.36 0.40 0.25 0.32 0.32 0.48 0.31 0.11 0.25 0.30 0.43 0.60 0.39 0.34\n",
      "Llama 2\n",
      "7B 0.28 0.25 0.29 0.50 0.36 0.37 0.21 0.34 0.32 0.50 0.28 0.19 0.26 0.32 0.44 0.51 0.30 0.2513B 0.24 0.25 0.35 0.50 0.41 0.36 0.24 0.39 0.35 0.48 0.31 0.18 0.27 0.34 0.46 0.66 0.35 0.2834B 0.27 0.24 0.33 0.56 0.41 0.36 0.26 0.32 0.36 0.53 0.33 0.07 0.26 0.30 0.45 0.56 0.26 0.3570B 0.31 0.29 0.35 0.51 0.41 0.45 0.27 0.34 0.40 0.52 0.36 0.12 0.28 0.31 0.45 0.65 0.33 0.20\n",
      "Fine-tuned\n"
     ]
    }
   ],
   "source": [
    "print(relevant_doc[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde6efbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
